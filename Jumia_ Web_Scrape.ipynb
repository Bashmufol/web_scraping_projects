{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d687d29b",
   "metadata": {},
   "source": [
    "# Intoduction\n",
    "\n",
    "Jumia is a Pan-African technology company that is built around a marketplace, logistics service and payment service. In this Project I will be scraping some informations about the laptops for sale on the jumia website then export it into excel file for basic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912e944",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce91a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e44d0",
   "metadata": {},
   "source": [
    "### Get Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46699433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store the website in a variable and get the status code\n",
    "website = 'https://www.jumia.com.ng/catalog/?q=laptops'\n",
    "response = requests.get(website)\n",
    "response.status_code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008550be",
   "metadata": {},
   "source": [
    "### Soup Object\n",
    "Since Status code of the request returns 200 that means the website is permitted and avaliable for scraping, we will proceed with creating the soup object for parsing through the contents of the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e90320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "print(soup.prettify()) #prints the content of the webpage in a more organized way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278d248",
   "metadata": {},
   "source": [
    "### Results\n",
    "After successfully parsing through the webpage, we can now find the information we want, in this case the body section of each laptop on sale by pulling the html tag which includes the link, image of the laptop, description, price, review etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfb8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = soup.find_all('a', {'class':'core'})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b0447a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the total number of laptop extracted from the page\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dacec88",
   "metadata": {},
   "source": [
    "### Observation\n",
    "We can see that there are currently 40 laptops posted on the first(current) webpage of jumia laptop category as ret. We can now start extracting the information we want from the first result of the results variable before proceeding to extracting the whole page and then all the pages in the laptop category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf8f04d",
   "metadata": {},
   "source": [
    "## Target Necessary Data\n",
    "Here we target the particular data we want from the html content extracted to the results variable above. Below are the neccesary data we would be targeting in this project.\n",
    "#### Product details\n",
    "Consists of product name and some informations about the product\n",
    "#### Product Price\n",
    "Price of the product\n",
    "#### Review ratings\n",
    "Number of review star for each products\n",
    "#### Store status\n",
    "Whether the product is posted by the official store or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdfbca9",
   "metadata": {},
   "source": [
    "### Product details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb21fc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lenovo V15-IGL Intel Celeron 1TB HDD 4GB RAM Win 10'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_details = results[0].find('h3', class_='name').get_text()\n",
    "product_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da67dd",
   "metadata": {},
   "source": [
    "### Product Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12baf31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â‚¦ 130,990'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = results[0].find('div', class_='prc').get_text()\n",
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92a5e1",
   "metadata": {},
   "source": [
    "### Review ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca69f3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_rating = results[0].find('div', class_='stars _s').get_text().split()[0]\n",
    "review_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63eb4d4",
   "metadata": {},
   "source": [
    "### Put everything together inside a For-Loop\n",
    "Here we create a list of the targeted data then loop through the first page to add the targeted data of all the laptops in the page to their respective list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1058ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name = []\n",
    "product_price = []\n",
    "rating = []\n",
    "store_status = []\n",
    "for result in results:\n",
    "    \n",
    "    #details\n",
    "        try:\n",
    "            product_name.append(result.find('h3', class_='name').get_text())\n",
    "        except:\n",
    "            product_name.append('n/a')\n",
    "            \n",
    "    #price        \n",
    "        try:\n",
    "            product_price.append(result.find('div', class_='prc').get_text())\n",
    "        except:\n",
    "            product_price.append('n/a')\n",
    "     \n",
    "    #review rating\n",
    "        try:\n",
    "            rating.append(result.find('div', class_='stars _s').get_text().split()[0]) \n",
    "        except:\n",
    "            rating.append('n/a')\n",
    "        \n",
    "    #store\n",
    "        try:\n",
    "            store_status.append(result.find('div', class_='bdg _mall _xs').get_text())\n",
    "        except:\n",
    "            store_status.append('Not Offical Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6efe0a",
   "metadata": {},
   "source": [
    "### PAGINATION\n",
    "As we did above we would be looping through pages but this time it will be all the pages under laptop category which consists of 51 pages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a00ea41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(2, 51):\n",
    "    \n",
    "    website = 'https://www.jumia.com.ng/catalog/?q=laptops&page='+str(num)+'#catalog-listing'\n",
    "    response = requests.get(website)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    results = soup.find_all('a', {'class':'core'})\n",
    "    #loop through each page\n",
    "    for result in results:\n",
    "        #name\n",
    "        try:\n",
    "            product_name.append(result.find('h3', class_='name').get_text())\n",
    "        except:\n",
    "            product_name.append('n/a')\n",
    "            \n",
    "    #price        \n",
    "        try:\n",
    "            product_price.append(result.find('div', class_='prc').get_text())\n",
    "        except:\n",
    "            product_price.append('n/a')\n",
    "     \n",
    "    #review rating\n",
    "        try:\n",
    "            rating.append(result.find('div', class_='stars _s').get_text().split()[0]) \n",
    "        except:\n",
    "            rating.append('n/a')\n",
    "        \n",
    "        #store\n",
    "        try:\n",
    "            store_status.append(result.find('div', class_='bdg _mall _xs').get_text())\n",
    "        except:\n",
    "            store_status.append('Not Offical Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd14360",
   "metadata": {},
   "source": [
    "### Convert the data into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e4afd27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus 2021 14\" PC Intel Celeron N4020 4GB RAM-1...</td>\n",
       "      <td>â‚¦ 159,600</td>\n",
       "      <td>4</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hp Stream11Intel Celeron 32gb Mmc,2gbRamOnBoar...</td>\n",
       "      <td>â‚¦ 102,500</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itel IntelÂ® Celeronâ„¢ N3350, 4GB/1TB HDD 14\" La...</td>\n",
       "      <td>â‚¦ 147,500</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asus Mini Notebook Intel Celeron 4GB RAM 500GB...</td>\n",
       "      <td>â‚¦ 139,000</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Firman SUMEC FIRMAN 10000MAH SUPER STRONG RELI...</td>\n",
       "      <td>â‚¦ 7,272</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>Hp ProBook 11 X360- TouchScreen  - Intel Penti...</td>\n",
       "      <td>â‚¦ 355,000</td>\n",
       "      <td>5</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>Waterproof Dustproof Silicone Keyboard Cover F...</td>\n",
       "      <td>â‚¦ 1,723</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>DELL Inspiron 14 Intel Core I3 128GB SSD+1TB H...</td>\n",
       "      <td>â‚¦ 351,000</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>Hp Pavilion 14 X360-Intel Core I3 Backlit Keyb...</td>\n",
       "      <td>â‚¦ 400,000</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>Hp 15 Intel Core I7- 12GB RAM-1TB HDD, 2GB NVI...</td>\n",
       "      <td>â‚¦ 510,000</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Not Offical Store</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3920 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name      Price Rating  \\\n",
       "0     Asus 2021 14\" PC Intel Celeron N4020 4GB RAM-1...  â‚¦ 159,600      4   \n",
       "1     Hp Stream11Intel Celeron 32gb Mmc,2gbRamOnBoar...  â‚¦ 102,500      1   \n",
       "2     itel IntelÂ® Celeronâ„¢ N3350, 4GB/1TB HDD 14\" La...  â‚¦ 147,500    n/a   \n",
       "3     Asus Mini Notebook Intel Celeron 4GB RAM 500GB...  â‚¦ 139,000    n/a   \n",
       "4     Firman SUMEC FIRMAN 10000MAH SUPER STRONG RELI...    â‚¦ 7,272    n/a   \n",
       "...                                                 ...        ...    ...   \n",
       "3915  Hp ProBook 11 X360- TouchScreen  - Intel Penti...  â‚¦ 355,000      5   \n",
       "3916  Waterproof Dustproof Silicone Keyboard Cover F...    â‚¦ 1,723    n/a   \n",
       "3917  DELL Inspiron 14 Intel Core I3 128GB SSD+1TB H...  â‚¦ 351,000    n/a   \n",
       "3918  Hp Pavilion 14 X360-Intel Core I3 Backlit Keyb...  â‚¦ 400,000    n/a   \n",
       "3919  Hp 15 Intel Core I7- 12GB RAM-1TB HDD, 2GB NVI...  â‚¦ 510,000    n/a   \n",
       "\n",
       "                  store  \n",
       "0     Not Offical Store  \n",
       "1     Not Offical Store  \n",
       "2     Not Offical Store  \n",
       "3     Not Offical Store  \n",
       "4     Not Offical Store  \n",
       "...                 ...  \n",
       "3915  Not Offical Store  \n",
       "3916  Not Offical Store  \n",
       "3917  Not Offical Store  \n",
       "3918  Not Offical Store  \n",
       "3919  Not Offical Store  \n",
       "\n",
       "[3920 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name':product_name,'Price':product_price,'Rating':rating,'store':store_status})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e292f",
   "metadata": {},
   "source": [
    "### Export into an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51070d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('laptop_data.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
